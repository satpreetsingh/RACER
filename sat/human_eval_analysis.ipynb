{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(20, 28)\n",
      "(20, 28)\n",
      "       Q14  Q15        Q16  Q17  Q18  Q19  Q20  Q21  Q22  Q23  ...  Q32   \n",
      "C003     1    1    1,2,3,5    1    1    4    3    3    1    1  ...    1  \\\n",
      "C014  1, 4    1  1,2,4,6,8    1    1    3    3    2    1    1  ...    1   \n",
      "C018  1, 4    1          5    1    2    4    3    2    1    2  ...    3   \n",
      "C019     3    1    3, 4, 5    1    2    3    3    3    1    1  ...    1   \n",
      "C028     2    1     1, 5,8    1    1    4    3    4    1    2  ...    1   \n",
      "\n",
      "      Q32.1  Q34  Q35  Q36  Q37  Q38  Q39  Q40  Q41  \n",
      "C003      2    1    1    2    2    1    1    -    -  \n",
      "C014      2    3    1    1    1    4    2    -    -  \n",
      "C018      2    2    1    1    1    3    1    -    -  \n",
      "C019      2    1    1    2    3    2    1    -    -  \n",
      "C028      2    1    1    2    3    1    2    -    -  \n",
      "\n",
      "[5 rows x 28 columns]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "INPUT_DIR = \"../data/human_eval/\"\n",
    "he1 = pd.read_csv(f\"{INPUT_DIR}/Human_evaluation_results_E1.csv\", index_col=0).dropna()\n",
    "he1  # Missing Row 14?\n",
    "print(he1.shape)\n",
    "he2 = pd.read_csv(f\"{INPUT_DIR}/Human_evaluation_results_E2.csv\", index_col=0).dropna()\n",
    "print(he2.shape)\n",
    "print(he2.head())\n",
    "# he3 = pd.read_csv(f\"{INPUT_DIR}/Mastersheet_human_evaluation_results_combined_E1E2.csv\")\n",
    "# print(he3.shape)\n",
    "# he3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.21459876543209874\n",
      "[0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import itertools\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Assuming 'he1' and 'he2' are already loaded as shown in your code snippet\n",
    "\n",
    "\n",
    "def preprocess_data(df):\n",
    "    \"\"\"Preprocess the dataframe to convert cluster assignments to sets.\"\"\"\n",
    "    for col in df.columns:\n",
    "        df[col] = df[col].apply(lambda x: set(map(str.strip, str(x).split(\",\"))))\n",
    "    return df\n",
    "\n",
    "\n",
    "\n",
    "def calculate_overall_agreement(df1, df2, agreement_func):\n",
    "    \"\"\"\n",
    "    Calculate the overall and per-question agreement between two dataframes\n",
    "    using the provided agreement function.\n",
    "    \"\"\"\n",
    "    total_agreement = 0\n",
    "    total_possible = 0\n",
    "    question_agreements = {q: [] for q in df1.columns}\n",
    "\n",
    "    for col in df1.columns:\n",
    "        for idx in df1.index:\n",
    "            # Ensure the subject exists in both dataframes and in the same column\n",
    "            if idx in df2.index and col in df2.columns:\n",
    "                agreement = agreement_func(df1.at[idx, col], df2.at[idx, col])\n",
    "                total_agreement += agreement\n",
    "                total_possible += 1\n",
    "                question_agreements[col].append(agreement)\n",
    "\n",
    "    # Calculate average agreement\n",
    "    average_agreement = total_agreement / total_possible if total_possible else 0\n",
    "    return average_agreement, question_agreements\n",
    "\n",
    "\n",
    "# Preprocess data\n",
    "he1_preprocessed = preprocess_data(he1)\n",
    "he2_preprocessed = preprocess_data(he2)\n",
    "\n",
    "# Calculate overall agreement and per-question agreement using the dummy data\n",
    "overall_agreement, per_question_agreements = calculate_overall_agreement(\n",
    "    he1_preprocessed, he2_preprocessed, calculate_individual_agreement\n",
    ")\n",
    "\n",
    "print(overall_agreement)\n",
    "print(per_question_agreements[\"Q14\"])  # Example output for one question"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
