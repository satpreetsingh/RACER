{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing 42 response files...\n",
      "outputs/20231209/clusters/A_0.txt |\n",
      "outputs/20231209/clusters/A_1.txt |\n",
      "outputs/20231209/clusters/A_10.txt |\n",
      "outputs/20231209/clusters/A_11.txt |\n",
      "outputs/20231209/clusters/A_12.txt |\n",
      "outputs/20231209/clusters/A_13.txt |\n",
      "outputs/20231209/clusters/A_14.txt |\n",
      "outputs/20231209/clusters/A_15.txt |\n",
      "outputs/20231209/clusters/A_16.txt |\n",
      "outputs/20231209/clusters/A_17.txt |\n",
      "outputs/20231209/clusters/A_18.txt |\n",
      "outputs/20231209/clusters/A_19.txt |\n",
      "outputs/20231209/clusters/A_2.txt |\n",
      "outputs/20231209/clusters/A_20.txt |\n",
      "outputs/20231209/clusters/A_21.txt |\n",
      "outputs/20231209/clusters/A_22.txt |\n",
      "outputs/20231209/clusters/A_23.txt |\n",
      "outputs/20231209/clusters/A_24.txt |\n",
      "outputs/20231209/clusters/A_25.txt |\n",
      "outputs/20231209/clusters/A_26.txt |\n",
      "outputs/20231209/clusters/A_27.txt |\n",
      "outputs/20231209/clusters/A_28.txt |\n",
      "outputs/20231209/clusters/A_29.txt |\n",
      "outputs/20231209/clusters/A_3.txt |\n",
      "outputs/20231209/clusters/A_30.txt |\n",
      "outputs/20231209/clusters/A_31.txt |\n",
      "outputs/20231209/clusters/A_32.txt |\n",
      "outputs/20231209/clusters/A_33.txt |\n",
      "outputs/20231209/clusters/A_34.txt |\n",
      "outputs/20231209/clusters/A_35.txt |\n",
      "outputs/20231209/clusters/A_36.txt |\n",
      "outputs/20231209/clusters/A_37.txt |\n",
      "outputs/20231209/clusters/A_38.txt |\n",
      "outputs/20231209/clusters/A_39.txt |\n",
      "outputs/20231209/clusters/A_4.txt |\n",
      "outputs/20231209/clusters/A_40.txt |\n",
      "outputs/20231209/clusters/A_41.txt |\n",
      "outputs/20231209/clusters/A_5.txt |\n",
      "outputs/20231209/clusters/A_6.txt |\n",
      "outputs/20231209/clusters/A_7.txt |\n",
      "outputs/20231209/clusters/A_8.txt |\n",
      "outputs/20231209/clusters/A_9.txt |\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import glob\n",
    "from io import StringIO\n",
    "import utils\n",
    "\n",
    "ALL_SUBJECT_IDS = utils.get_all_subject_ids()\n",
    "\n",
    "INPUTS_DIR = \"outputs/20231209/clusters/\"\n",
    "OUTPUT_DIR = \"outputs/20231209/clusters/\"\n",
    "OUTPUT_EXCEL_FILE = f\"{OUTPUT_DIR}/clusters_structured.xlsx\"\n",
    "\n",
    "\n",
    "def read_dataframe(content):\n",
    "    \"\"\"Try to read the data with tab and comma delimiters. Return the dataframe.\"\"\"\n",
    "    try:\n",
    "        df = pd.read_csv(StringIO(content), sep=\"\\t\")\n",
    "        if df.shape[1] < 2:\n",
    "            df = pd.read_csv(StringIO(content), sep=\",\", skipinitialspace=True)\n",
    "    except Exception as e:\n",
    "        df = pd.DataFrame()\n",
    "    return df\n",
    "\n",
    "\n",
    "data = {}\n",
    "error_files = []\n",
    "response_files = sorted(glob.glob(f\"{INPUTS_DIR}/A_*.txt\"))\n",
    "print(f\"Processing {len(response_files)} response files...\")\n",
    "for file in response_files:\n",
    "    try:\n",
    "        # Read the two tables in the file\n",
    "        # The first table is from the first row to the empty row\n",
    "        # The second table starts after the empty row\n",
    "        with open(file, \"r\") as f:\n",
    "            # This fails because GPT inserts random newlines\n",
    "            content = f.read()\n",
    "            tables = content.strip().split(\n",
    "                \"\\n\\n\"\n",
    "            )  # Split by two newlines to get the two tables\n",
    "            table1 = tables[0].strip()\n",
    "            table2 = tables[1].strip()\n",
    "\n",
    "            # Remove empty lines before parsing\n",
    "            # lines = f.readlines()\n",
    "            # non_empty_lines = [line for line in lines if line.strip()]\n",
    "            # content = ''.join(non_empty_lines)\n",
    "            # parts = content.split(\"subject_id\")\n",
    "            # # The first table is the data before the term \"subject_id\"\n",
    "            # table1 = parts[0].strip()\n",
    "            # # The second table starts with \"subject_id\" followed by the rest of the content after the split\n",
    "            # table2 = \"subject_id\" + parts[1].strip()\n",
    "\n",
    "            # print(file, len(tables), len(tables[0]), len(tables[1]))\n",
    "            # print(tables[0][:80])\n",
    "            # print(tables[0][-80:])\n",
    "            # print(tables[1][:200])\n",
    "            # print(tables[1][-80:])\n",
    "\n",
    "        # Convert into dataframes\n",
    "        cluster_metadata_df = read_dataframe(table1)\n",
    "        clustering_df = read_dataframe(table2)\n",
    "        file_number = int(file.split(\"_\")[-1].split(\".\")[0])\n",
    "        data[file_number] = (cluster_metadata_df, clustering_df)\n",
    "\n",
    "        # Check for errors\n",
    "        errors = [\"|\"]\n",
    "        if cluster_metadata_df.shape[1] != 3:\n",
    "            errors.append(f\"Metadata: {cluster_metadata_df.shape} is not (n, 3)\")\n",
    "        if clustering_df.shape[0] != 93 or clustering_df.shape[1] not in [2, 3]:\n",
    "            errors.append(f\"Clusters: {clustering_df.shape} is not (93, n)\")\n",
    "        missing_subject_ids = set(ALL_SUBJECT_IDS) - set(\n",
    "            clustering_df[\"subject_id\"].to_list()\n",
    "        )\n",
    "        extra_subject_ids = set(clustering_df[\"subject_id\"].to_list()) - set(\n",
    "            ALL_SUBJECT_IDS\n",
    "        )\n",
    "        if missing_subject_ids:\n",
    "            errors.append(f\"Missing subject_ids: {missing_subject_ids}\")\n",
    "        if extra_subject_ids:\n",
    "            errors.append(f\"Extra subject_ids: {extra_subject_ids}\")\n",
    "        print(file, \" \".join(errors))\n",
    "        if errors != [\"|\"]:\n",
    "            error_files.append(file)\n",
    "\n",
    "    except Exception as e:\n",
    "        error_files.append(file)\n",
    "        print(f\"Error in {file}: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "error_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved outputs/20231209/clusters//Q00_metadata.csv and outputs/20231209/clusters//Q00_clusters.csv\n",
      "Saved outputs/20231209/clusters//Q01_metadata.csv and outputs/20231209/clusters//Q01_clusters.csv\n",
      "Saved outputs/20231209/clusters//Q02_metadata.csv and outputs/20231209/clusters//Q02_clusters.csv\n",
      "Saved outputs/20231209/clusters//Q03_metadata.csv and outputs/20231209/clusters//Q03_clusters.csv\n",
      "Saved outputs/20231209/clusters//Q04_metadata.csv and outputs/20231209/clusters//Q04_clusters.csv\n",
      "Saved outputs/20231209/clusters//Q05_metadata.csv and outputs/20231209/clusters//Q05_clusters.csv\n",
      "Saved outputs/20231209/clusters//Q06_metadata.csv and outputs/20231209/clusters//Q06_clusters.csv\n",
      "Saved outputs/20231209/clusters//Q07_metadata.csv and outputs/20231209/clusters//Q07_clusters.csv\n",
      "Saved outputs/20231209/clusters//Q08_metadata.csv and outputs/20231209/clusters//Q08_clusters.csv\n",
      "Saved outputs/20231209/clusters//Q09_metadata.csv and outputs/20231209/clusters//Q09_clusters.csv\n",
      "Saved outputs/20231209/clusters//Q10_metadata.csv and outputs/20231209/clusters//Q10_clusters.csv\n",
      "Saved outputs/20231209/clusters//Q11_metadata.csv and outputs/20231209/clusters//Q11_clusters.csv\n",
      "Saved outputs/20231209/clusters//Q12_metadata.csv and outputs/20231209/clusters//Q12_clusters.csv\n",
      "Saved outputs/20231209/clusters//Q13_metadata.csv and outputs/20231209/clusters//Q13_clusters.csv\n",
      "Saved outputs/20231209/clusters//Q14_metadata.csv and outputs/20231209/clusters//Q14_clusters.csv\n",
      "Saved outputs/20231209/clusters//Q15_metadata.csv and outputs/20231209/clusters//Q15_clusters.csv\n",
      "Saved outputs/20231209/clusters//Q16_metadata.csv and outputs/20231209/clusters//Q16_clusters.csv\n",
      "Saved outputs/20231209/clusters//Q17_metadata.csv and outputs/20231209/clusters//Q17_clusters.csv\n",
      "Saved outputs/20231209/clusters//Q18_metadata.csv and outputs/20231209/clusters//Q18_clusters.csv\n",
      "Saved outputs/20231209/clusters//Q19_metadata.csv and outputs/20231209/clusters//Q19_clusters.csv\n",
      "Saved outputs/20231209/clusters//Q20_metadata.csv and outputs/20231209/clusters//Q20_clusters.csv\n",
      "Saved outputs/20231209/clusters//Q21_metadata.csv and outputs/20231209/clusters//Q21_clusters.csv\n",
      "Saved outputs/20231209/clusters//Q22_metadata.csv and outputs/20231209/clusters//Q22_clusters.csv\n",
      "Saved outputs/20231209/clusters//Q23_metadata.csv and outputs/20231209/clusters//Q23_clusters.csv\n",
      "Saved outputs/20231209/clusters//Q24_metadata.csv and outputs/20231209/clusters//Q24_clusters.csv\n",
      "Saved outputs/20231209/clusters//Q25_metadata.csv and outputs/20231209/clusters//Q25_clusters.csv\n",
      "Saved outputs/20231209/clusters//Q26_metadata.csv and outputs/20231209/clusters//Q26_clusters.csv\n",
      "Saved outputs/20231209/clusters//Q27_metadata.csv and outputs/20231209/clusters//Q27_clusters.csv\n",
      "Saved outputs/20231209/clusters//Q28_metadata.csv and outputs/20231209/clusters//Q28_clusters.csv\n",
      "Saved outputs/20231209/clusters//Q29_metadata.csv and outputs/20231209/clusters//Q29_clusters.csv\n",
      "Saved outputs/20231209/clusters//Q30_metadata.csv and outputs/20231209/clusters//Q30_clusters.csv\n",
      "Saved outputs/20231209/clusters//Q31_metadata.csv and outputs/20231209/clusters//Q31_clusters.csv\n",
      "Saved outputs/20231209/clusters//Q32_metadata.csv and outputs/20231209/clusters//Q32_clusters.csv\n",
      "Saved outputs/20231209/clusters//Q33_metadata.csv and outputs/20231209/clusters//Q33_clusters.csv\n",
      "Saved outputs/20231209/clusters//Q34_metadata.csv and outputs/20231209/clusters//Q34_clusters.csv\n",
      "Saved outputs/20231209/clusters//Q35_metadata.csv and outputs/20231209/clusters//Q35_clusters.csv\n",
      "Saved outputs/20231209/clusters//Q36_metadata.csv and outputs/20231209/clusters//Q36_clusters.csv\n",
      "Saved outputs/20231209/clusters//Q37_metadata.csv and outputs/20231209/clusters//Q37_clusters.csv\n",
      "Saved outputs/20231209/clusters//Q38_metadata.csv and outputs/20231209/clusters//Q38_clusters.csv\n",
      "Saved outputs/20231209/clusters//Q39_metadata.csv and outputs/20231209/clusters//Q39_clusters.csv\n",
      "Saved outputs/20231209/clusters//Q40_metadata.csv and outputs/20231209/clusters//Q40_clusters.csv\n",
      "Saved outputs/20231209/clusters//Q41_metadata.csv and outputs/20231209/clusters//Q41_clusters.csv\n",
      "All data saved to outputs/20231209/clusters//clusters_structured.xlsx\n"
     ]
    }
   ],
   "source": [
    "with pd.ExcelWriter(OUTPUT_EXCEL_FILE) as writer:\n",
    "    for file_number, (metadata_df, clusters_df) in sorted(data.items()):\n",
    "        file_number = f\"{file_number:02d}\"\n",
    "        metadata_df.to_excel(writer, sheet_name=f\"Q{file_number}_metadata\", index=False)\n",
    "        clusters_df.to_excel(writer, sheet_name=f\"Q{file_number}_clusters\", index=False)\n",
    "\n",
    "        fn_meta = f\"{OUTPUT_DIR}/Q{file_number}_metadata.csv\"\n",
    "        metadata_df.to_csv(fn_meta, index=False)\n",
    "        fn_clusters = f\"{OUTPUT_DIR}/Q{file_number}_clusters.csv\"\n",
    "        clusters_df.to_csv(fn_clusters, index=False)\n",
    "        print(f\"Saved {fn_meta} and {fn_clusters}\")\n",
    "\n",
    "print(f\"All data saved to {OUTPUT_EXCEL_FILE}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data\n",
    "# Create a merged dataframe\n",
    "# merged_df = clustering_df.copy()\n",
    "# cluster_ids = merged_df['cluster_ids'].str.split(',', expand=True)\n",
    "# for i in range(cluster_ids.shape[1]):\n",
    "#     col_name = f\"cluster_name_{i+1}\"\n",
    "#     merged_df[col_name] = cluster_ids[i].map(cluster_metadata_df.set_index('cluster_id')['cluster_name'])\n",
    "\n",
    "# cmap = cluster_metadata_df.set_index('cluster_id')['cluster_name']\n",
    "\n",
    "# clustering_df[\"secondary_cluster_ids\"] #.str.replace(\"C\",\"\") #.map(cmap)\n",
    "# cmap\n",
    "# clustering_df[\"secondary_cluster_ids\"].str.split(',', expand=True).stack().map(cmap).unstack()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ALL_SUBJECT_IDS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
